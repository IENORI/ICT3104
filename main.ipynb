{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOMrR61w_bGv"
      },
      "source": [
        "# Imports and Setup\n",
        "To begin, run the cell(s) below to install the necessary setup and imports."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3.8"
      ],
      "metadata": {
        "id": "0PwOWiNzhegn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.8 --version"
      ],
      "metadata": {
        "id": "vW2RFkGuh46M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "pxWGK0bqjGxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.8 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "id": "I4ARS8SjjXR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda update -n base -c defaults conda --yes"
      ],
      "metadata": {
        "id": "ws4PuRicjk5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.8/site-packages\"))"
      ],
      "metadata": {
        "id": "GVvtCvxljuDm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "metadata": {
        "id": "d0dmViG4jw7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda init zsh"
      ],
      "metadata": {
        "id": "VGSl_B0HkRny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create --name env python=3.8 --yes"
      ],
      "metadata": {
        "id": "z9jZgmDGkVLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /usr/local/bin/activate env"
      ],
      "metadata": {
        "id": "vf_l0kymkykQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "pip install timm==0.4.12\n",
        "pip install pickle5\n",
        "pip install scikit-learn\n",
        "pip install numpy"
      ],
      "metadata": {
        "id": "NmEYB0j7kndK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z4LR7I3bmA8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "JYSHgwNiGhRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Toyota_Smarthome-main/pipline/"
      ],
      "metadata": {
        "id": "GtgMpEusHd3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.8 /content/drive/MyDrive/Toyota_Smarthome-main/pipline/train.py --help"
      ],
      "metadata": {
        "id": "fcFnBIuWp6Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.8 /content/drive/MyDrive/Toyota_Smarthome-main/pipline/train.py \\\n",
        "-dataset TSU \\\n",
        "-mode rgb \\\n",
        "-split_setting CS \\\n",
        "-model PDAN \\\n",
        "-num_channel 512 \\\n",
        "-lr 0.0002 \\\n",
        "-kernelsize 3 \\\n",
        "-APtype map \\\n",
        "-epoch 15 \\\n",
        "-batch_size 1 \\\n",
        "-comp_info TSU_CS_RGB_PDAN \\\n",
        "-load_model /content/drive/MyDrive/Toyota_Smarthome-main/model/PDAN_TSU_RGB \\\n",
        "-rgb_model_file P02T01C06"
      ],
      "metadata": {
        "id": "vphwH6-UmOxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "dgiMiBoIV5qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing Constants"
      ],
      "metadata": {
        "id": "T1zq4T-5uvwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INITIALIZING PATH VARIABLES (CHANGE HERE IF DIFFERENT DIRECTORY)\n",
        "\n",
        "PATH_TO_MODEL_FOLDER = \"/content/drive/MyDrive/Toyota_Smarthome-main/model/\"\n",
        "PATH_TO_VIDEO_FOLDER = \"/content/drive/MyDrive/Toyota_Smarthome-main/video/\"\n",
        "PATH_TO_FEATURE_FOLDER = \"/content/drive/MyDrive/Toyota_Smarthome-main/feature_file/\""
      ],
      "metadata": {
        "id": "QGT1zqXUgk2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# R2\n",
        "\n",
        "Data Exploration Section:\n",
        "- Check out the different input videos (with UI)\n",
        "- See playback of video"
      ],
      "metadata": {
        "id": "WTACA4lscDEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "\n",
        "videoList = os.listdir(PATH_TO_VIDEO_FOLDER)\n",
        "\n",
        "video = widgets.Dropdown(\n",
        "    options = videoList,\n",
        "    description='Video:',\n",
        "    disabled=False,\n",
        ")\n",
        "video"
      ],
      "metadata": {
        "id": "Gb6DxBP2WeiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "VIDEO_SELECTED = PATH_TO_VIDEO_FOLDER + video.value\n",
        "Video(VIDEO_SELECTED)"
      ],
      "metadata": {
        "id": "R1GDNZr0baRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# R3\n",
        "Inference Section:\n",
        "- Load a pretrained model (with UI)\n",
        "- Choose input video (with UI)\n",
        "- See inference result in the form out output video with captions that indicte the current detected activity in each video frame"
      ],
      "metadata": {
        "id": "XDcXbPzjDmol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "\n",
        "modelList = os.listdir(PATH_TO_MODEL_FOLDER)\n",
        "\n",
        "model = widgets.Dropdown(\n",
        "    options = modelList,\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "box = widgets.Box(children = [model, video])\n",
        "box"
      ],
      "metadata": {
        "id": "HaitC-8gNOyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finalized chosen model and video directory\n",
        "\n",
        "SELECTED_MODEL = PATH_TO_MODEL_FOLDER + model.value\n",
        "SELECTED_VIDEO = PATH_TO_VIDEO_FOLDER + video.value\n",
        "print(SELECTED_MODEL)\n",
        "print(SELECTED_VIDEO)"
      ],
      "metadata": {
        "id": "o_OH7IVnf8_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURE EXTRACTION\n",
        "\n",
        "TSU I3D Feature Extraction from video"
      ],
      "metadata": {
        "id": "n3Os38TsBEJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Toyota_Smarthome-main/feature_extract/\n",
        "\n",
        "! git clone https://github.com/v-iashin/video_features.git\n",
        "! pip install omegaconf==2.0.6 av==8.0.2"
      ],
      "metadata": {
        "id": "PkcPdmhwvHB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "PzakLfzZvc-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Toyota_Smarthome-main/feature_extract/video_features"
      ],
      "metadata": {
        "id": "x3BArtfuxoq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.i3d.extract_i3d import ExtractI3D\n",
        "from utils.utils import build_cfg_path\n",
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "zFACVHvXxsvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: RE-ADJUST THE DIRECTORY TO BE TO FEATURE_FILE"
      ],
      "metadata": {
        "id": "vQ83bnIhyg_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: RE-ADJUST TRAIN_CUSTOM.PY"
      ],
      "metadata": {
        "id": "rlGqDOZwymjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the feature type\n",
        "feature_type = 'i3d'\n",
        "\n",
        "# Load and patch the config\n",
        "args = OmegaConf.load(build_cfg_path(feature_type))\n",
        "args.video_paths = ['/content/drive/MyDrive/Toyota_Smarthome-main/pipline/data/videos/sample_videos/sample_video_1.mp4']\n",
        "# args.show_pred = True\n",
        "# args.stack_size = 24\n",
        "# args.step_size = 24\n",
        "# args.extraction_fps = 25\n",
        "args.flow_type = 'raft' # 'pwc' is not supported on Google Colab (cupy version mismatch)\n",
        "# args.streams = 'flow'\n",
        "\n",
        "# Load the model\n",
        "extractor = ExtractI3D(args)\n",
        "\n",
        "# Extract features\n",
        "for video_path in args.video_paths:\n",
        "    # extract name of video from video path (and remove '.mp4' suffix)\n",
        "    video_name = (video_path.split('/')[-1]).split('.')[0]\n",
        "    print(video_name)\n",
        "    print(f'Extracting for {video_path}')\n",
        "    feature_dict = extractor.extract(video_path)\n",
        "    print(feature_dict.items())\n",
        "    for k, v in feature_dict.items():\n",
        "      print(k)\n",
        "      print(v.shape)\n",
        "      print(v)\n",
        "      if k == \"rgb\":\n",
        "        np.save(f'/content/drive/MyDrive/Toyota_Smarthome-main/pipline/data/extracted_features/rgb/{video_name}_rgb', v)\n",
        "      elif k == \"flow\":\n",
        "        np.save(f'/content/drive/MyDrive/Toyota_Smarthome-main/pipline/data/extracted_features/flow/{video_name}_flow', v)\n",
        "      elif k == \"fps\":\n",
        "        np.save(f'/content/drive/MyDrive/Toyota_Smarthome-main/pipline/data/extracted_features/fps/{video_name}_fps', v)\n",
        "      elif k == \"timestamps_ms\":\n",
        "        np.save(f'/content/drive/MyDrive/Toyota_Smarthome-main/pipline/data/extracted_features/timestamps_ms/{video_name}_timestamps_ms', v)\n",
        "      else:\n",
        "        raise NotImplementedError(\"Error: Unexpected item in feature_dict!\")"
      ],
      "metadata": {
        "id": "IsdOnUibx1ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.load('/content/drive/MyDrive/Toyota_Smarthome-main/pipline/data/extracted_features/rgb/sample_video_1_rgb.npy')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "q9HiiNnmx2vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R3.3\n",
        "See inference results in the form of an output video with captions that indicate the current detected activity in each video frame"
      ],
      "metadata": {
        "id": "jjitUIcQ_8ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a Caption Model**"
      ],
      "metadata": {
        "id": "nbWGBC9tgLAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pafy youtube-dl moviepy\n",
        "!pip install imageio-ffmpeg\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import pafy\n",
        "import imageio\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "l1_zf_DZgOsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_constant = 23\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ],
      "metadata": {
        "id": "GzxY9p2Cg3Sq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HZK5VaWRxjre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget -nc --no-check-certificate https://www.crcv.ucf.edu/data/UCF50.rar\n",
        "#!unrar x UCF50.rar -inul -y"
      ],
      "metadata": {
        "id": "XNB3bHB-hLp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Toyota_Smarthome-main/video"
      ],
      "metadata": {
        "id": "bNiaNscZ5S02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Matplotlib figure\n",
        "plt.figure(figsize = (30, 30))\n",
        "\n",
        "# Get Names of all classes in UCF50\n",
        "all_classes_names = os.listdir('trainVideos')\n",
        "\n",
        "# Generate a random sample of images each time the cell runs\n",
        "random_range = random.sample(range(len(all_classes_names)), 7)\n",
        "\n",
        "# Iterating through all the random samples\n",
        "for counter, random_index in enumerate(random_range, 1):\n",
        "\n",
        "    # Getting Class Name using Random Index\n",
        "    selected_class_Name = all_classes_names[random_index]\n",
        "\n",
        "    # Getting a list of all the video files present in a Class Directory\n",
        "    video_files_names_list = os.listdir(f'trainVideos/{selected_class_Name}')\n",
        "\n",
        "    # Randomly selecting a video file\n",
        "    selected_video_file_name = random.choice(video_files_names_list)\n",
        "\n",
        "    # Reading the Video File Using the Video Capture\n",
        "    video_reader = cv2.VideoCapture(f'trainVideos/{selected_class_Name}/{selected_video_file_name}')\n",
        "    \n",
        "    # Reading The First Frame of the Video File\n",
        "    _, bgr_frame = video_reader.read()\n",
        "\n",
        "    # Closing the VideoCapture object and releasing all resources. \n",
        "    video_reader.release()\n",
        "\n",
        "    # Converting the BGR Frame to RGB Frame \n",
        "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Adding The Class Name Text on top of the Video Frame.\n",
        "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    \n",
        "    # Assigning the Frame to a specific position of a subplot\n",
        "    plt.subplot(5, 4, counter)\n",
        "    plt.imshow(rgb_frame)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "Tpeu7IXShDLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_height, image_width = 64, 64\n",
        "max_images_per_class = 5000 #if less videos in each class, need the change the number down\n",
        "\n",
        "dataset_directory = \"trainVideos\"\n",
        "classes_list = [\"Weighlifting\",\"WalkingWithDog\",\"Knitting\",\"PushUps\",\"PlayingViolin\",\"PlayingGuitar\",\"PlayingPiano\"]\n",
        "\n",
        "model_output_size = len(classes_list)"
      ],
      "metadata": {
        "id": "XyuT9CQwmxps"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_extraction(video_path):\n",
        "    # Empty List declared to store video frames\n",
        "    frames_list = []\n",
        "    \n",
        "    # Reading the Video File Using the VideoCapture\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Iterating through Video Frames\n",
        "    while True:\n",
        "\n",
        "        # Reading a frame from the video file \n",
        "        success, frame = video_reader.read() \n",
        "\n",
        "        # If Video frame was not successfully read then break the loop\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
        "        \n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "        \n",
        "        # Appending the normalized frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "    \n",
        "    # Closing the VideoCapture object and releasing all resources. \n",
        "    video_reader.release()\n",
        "\n",
        "    # returning the frames list \n",
        "    return frames_list"
      ],
      "metadata": {
        "id": "svKXRdBennwn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "\n",
        "    # Declaring Empty Lists to store the features and labels values.\n",
        "    temp_features = [] \n",
        "    features = []\n",
        "    labels = []\n",
        "    \n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(classes_list):\n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "        \n",
        "        # Getting the list of video files present in the specific class name directory\n",
        "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
        "\n",
        "        # Iterating through all the files present in the files list\n",
        "        for file_name in files_list:\n",
        "\n",
        "            # Construct the complete video path\n",
        "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
        "\n",
        "            # Calling the frame_extraction method for every video file path\n",
        "            frames = frames_extraction(video_file_path)\n",
        "\n",
        "            # Appending the frames to a temporary list.\n",
        "            temp_features.extend(frames)\n",
        "        \n",
        "        # Adding randomly selected frames to the features list\n",
        "        features.extend(random.sample(temp_features, max_images_per_class))\n",
        "\n",
        "        # Adding Fixed number of labels to the labels list\n",
        "        labels.extend([class_index] * max_images_per_class)\n",
        "        \n",
        "        # Emptying the temp_features list so it can be reused to store all frames of the next class.\n",
        "        temp_features.clear()\n",
        "\n",
        "    # Converting the features and labels lists to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)  \n",
        "\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "qRzzAPlgnzMK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = create_dataset()"
      ],
      "metadata": {
        "id": "5--I5EVt3qCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
        "one_hot_encoded_labels = to_categorical(labels)"
      ],
      "metadata": {
        "id": "YG1FYpAi67wm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = seed_constant)"
      ],
      "metadata": {
        "id": "4pt9Ju_w7BCL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a function that will construct our model\n",
        "def create_model():\n",
        "\n",
        "    # We will use a Sequential model for model construction\n",
        "    model = Sequential()\n",
        "\n",
        "    # Defining The Model Architecture\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
        "\n",
        "    # Printing the models summary\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Calling the create_model method\n",
        "model = create_model()\n",
        "\n",
        "print(\"Model Created Successfully!\")"
      ],
      "metadata": {
        "id": "-oZMyHUwHBXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Early Stopping Callback\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Adding loss, optimizer and metrics values to the model.\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "# Start Training\n",
        "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ],
      "metadata": {
        "id": "g0ryOTiXQaCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a useful name for our model, incase you're saving multiple models (OPTIONAL)\n",
        "model_name = f'captionModel_2Oct.h5'\n",
        "\n",
        "# Saving your Model\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "id": "aHYh9uNM_c2m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_live_video(video_file_path, output_file_path, window_size):\n",
        "\n",
        "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
        "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
        "\n",
        "    # Reading the Video File using the VideoCapture Object\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Getting the width and height of the video \n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
        "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
        "\n",
        "    while True: \n",
        "\n",
        "        # Reading The Frame\n",
        "        status, frame = video_reader.read() \n",
        "\n",
        "        if not status:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
        "        \n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        #normalized_frame = resized_frame / 255\n",
        "        normalized_frame = resized_frame\n",
        "\n",
        "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
        "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
        "\n",
        "        # Appending predicted label probabilities to the deque object\n",
        "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
        "\n",
        "        # Assuring that the Deque is completely filled before starting the averaging process\n",
        "        if len(predicted_labels_probabilities_deque) == window_size:\n",
        "\n",
        "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
        "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
        "\n",
        "            # Calculating Average of Predicted Labels Probabilities Column Wise \n",
        "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
        "\n",
        "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
        "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
        "\n",
        "            # Accessing The Class Name using predicted label.\n",
        "            predicted_class_name = classes_list[predicted_label]\n",
        "          \n",
        "            # Overlaying Class Name Text Ontop of the Frame\n",
        "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        # Writing The Frame\n",
        "        video_writer.write(frame)\n",
        "\n",
        "\n",
        "    #     cv2.imshow('Predicted Frames', frame)\n",
        "\n",
        "    #     key_pressed = cv2.waitKey(10)\n",
        "\n",
        "    #     if key_pressed == ord('q'):\n",
        "    #         break\n",
        "\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "    \n",
        "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them. \n",
        "    video_reader.release()\n",
        "    video_writer.release()"
      ],
      "metadata": {
        "id": "3_jkX4mgBHIq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting sthe Window Size which will be used by the Rolling Average Proces\n",
        "window_size = 1\n",
        "\n",
        "# Constructing The Output YouTube Video Path\n",
        "output_video_file_path = f'/content/drive/MyDrive/Toyota_Smarthome-main/video/test_ouput.mp4'\n",
        "input_video_file_path = f'/content/drive/MyDrive/Toyota_Smarthome-main/video/trainVideos/PlayingViolin/v_PlayingViolin_g01_c01.avi'\n",
        "\n",
        "# Calling the predict_on_live_video method to start the Prediction.\n",
        "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
        "\n",
        "# Play Video File in the Notebook"
      ],
      "metadata": {
        "id": "hH7LVqCVAXgc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Caption Model Staightway**"
      ],
      "metadata": {
        "id": "Az2IiIxorMql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "ZbFH7D1Ou05y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/Toyota_Smarthome-main/video/captionModel_new.h5')"
      ],
      "metadata": {
        "id": "CnwAJVpVqbuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_height, image_width = 64, 64\n",
        "classes_list = [\"WalkingWithDog\",\"Weighlifting\"]\n",
        "def predict_on_live_video(video_file_path, output_file_path, window_size):\n",
        "\n",
        "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
        "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
        "\n",
        "    # Reading the Video File using the VideoCapture Object\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Getting the width and height of the video \n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
        "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
        "\n",
        "    while True: \n",
        "\n",
        "        # Reading The Frame\n",
        "        status, frame = video_reader.read() \n",
        "\n",
        "        if not status:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
        "        \n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
        "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
        "\n",
        "        # Appending predicted label probabilities to the deque object\n",
        "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
        "\n",
        "        # Assuring that the Deque is completely filled before starting the averaging process\n",
        "        if len(predicted_labels_probabilities_deque) == window_size:\n",
        "\n",
        "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
        "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
        "\n",
        "            # Calculating Average of Predicted Labels Probabilities Column Wise \n",
        "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
        "\n",
        "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
        "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
        "\n",
        "            # Accessing The Class Name using predicted label.\n",
        "            predicted_class_name = classes_list[predicted_label]\n",
        "          \n",
        "            # Overlaying Class Name Text Ontop of the Frame\n",
        "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        # Writing The Frame\n",
        "        video_writer.write(frame)\n",
        "\n",
        "\n",
        "        # cv2.imshow('Predicted Frames', frame)\n",
        "\n",
        "        # key_pressed = cv2.waitKey(10)\n",
        "\n",
        "        # if key_pressed == ord('q'):\n",
        "        #     break\n",
        "\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "    \n",
        "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them. \n",
        "    video_reader.release()\n",
        "    video_writer.release()\n",
        "# Setting sthe Window Size which will be used by the Rolling Average Proces\n",
        "window_size = 20\n",
        "\n",
        "# Constructing The Output YouTube Video Path\n",
        "output_video_file_path = f'/content/drive/MyDrive/Toyota_Smarthome-main/video/outputnew3.mp4'\n",
        "input_video_file_path = f'/content/drive/MyDrive/Toyota_Smarthome-main/video/sample_video_1.mp4'\n",
        "\n",
        "# Calling the predict_on_live_video method to start the Prediction.\n",
        "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n"
      ],
      "metadata": {
        "id": "UhJarAjSrCFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# R4 \n",
        "\n",
        "- Choose a dataset subfolder to use for training (with UI)\n",
        "- Initialize a model with a network architecture configured in a separate .py file"
      ],
      "metadata": {
        "id": "TRTtFjBzmb0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "\n",
        "featureFolder = os.listdir(PATH_TO_FEATURE_FOLDER)\n",
        "\n",
        "feature = widgets.Dropdown(\n",
        "    options = featureFolder,\n",
        "    description='Feature:',\n",
        "    disabled=False,\n",
        ")\n",
        "feature\n"
      ],
      "metadata": {
        "id": "ba4LKCdDBJdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SELECTED_FEATURE = PATH_TO_FEATURE_FOLDER + feature.value\n",
        "print(SELECTED_FEATURE)"
      ],
      "metadata": {
        "id": "7aV1pfbcGTcd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}